{
 "metadata": {
  "name": "",
  "signature": "sha256:aafec776b7b45e8ec5b2cb4703618448480ee00aa06c09412c726e4f4658ed9e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "from pandas import DataFrame"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: pylab import has clobbered these variables: ['text', 'e']\n",
        "`%matplotlib` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Decision Trees</h1>\n",
      "\n",
      "From [Russel & Norvig \"Artificial Intelligence: A Modern Approach, 3rd Ed.\"](http://www.amazon.com/Artificial-Intelligence-Modern-Approach-Edition/dp/0136042597)\n",
      "\n",
      "Decision tree induction is one of the simplest and yet most successful forms of machine learning.\n",
      "\n",
      "A decision tree represents a function that takes as input a vector of attribute values and returns a \"decision\" -- a single output value.\n",
      "\n",
      "A decision tree reaches its decision by performing a sequence of tests. Each internal node in the tree corresponds to a test of the value of one of the input attributes. Each leaf node specifies a value to be returned by the function.\n",
      "\n",
      "A Boolean decision tree is logically equivalent to the assertion that the goal attribute is true if and only if the input attributes satisfy one of the paths leading to a leaf with value true.\n",
      "\n",
      "For a wide variety of problems, the decision tree format yields a nice, concise result. But some functions cannot be represented concisely. For example, the majority function, which returns true if and only if more than half of the inputs are true, requires an exponentially large decision tree. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = open(\"restaurant.txt\").read()\n",
      "data = text.split()\n",
      "better_data = {}\n",
      "for i,e in enumerate(data):\n",
      "    if e  == 'x':\n",
      "        better_data[data[i+1]] = data[i+1:i+15] \n",
      "                \n",
      "df = DataFrame(better_data).T\n",
      "\n",
      "del df[0]\n",
      "del df[11]\n",
      "del df[12]\n",
      "df.columns = ['alternatives','bar','Fri','hungry','patrons','$','rain','reservation','type','eta','eat?']\n",
      "df.index = range(1,13)\n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>alternatives</th>\n",
        "      <th>bar</th>\n",
        "      <th>Fri</th>\n",
        "      <th>hungry</th>\n",
        "      <th>patrons</th>\n",
        "      <th>$</th>\n",
        "      <th>rain</th>\n",
        "      <th>reservation</th>\n",
        "      <th>type</th>\n",
        "      <th>eta</th>\n",
        "      <th>eat?</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> Yes</td>\n",
        "      <td>  No</td>\n",
        "      <td>  No</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Some</td>\n",
        "      <td> $$$</td>\n",
        "      <td>  No</td>\n",
        "      <td> Yes</td>\n",
        "      <td>  French</td>\n",
        "      <td>  0-10</td>\n",
        "      <td> Yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> Yes</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Full</td>\n",
        "      <td> $$$</td>\n",
        "      <td>  No</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Italian</td>\n",
        "      <td> 10-30</td>\n",
        "      <td>  No</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>  No</td>\n",
        "      <td>  No</td>\n",
        "      <td>  No</td>\n",
        "      <td>  No</td>\n",
        "      <td> None</td>\n",
        "      <td>   $</td>\n",
        "      <td>  No</td>\n",
        "      <td>  No</td>\n",
        "      <td>    Thai</td>\n",
        "      <td>  0-10</td>\n",
        "      <td>  No</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> Yes</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Full</td>\n",
        "      <td>   $</td>\n",
        "      <td>  No</td>\n",
        "      <td>  No</td>\n",
        "      <td>  Burger</td>\n",
        "      <td> 30-60</td>\n",
        "      <td> Yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> Yes</td>\n",
        "      <td>  No</td>\n",
        "      <td>  No</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Full</td>\n",
        "      <td>   $</td>\n",
        "      <td>  No</td>\n",
        "      <td>  No</td>\n",
        "      <td>    Thai</td>\n",
        "      <td> 30-60</td>\n",
        "      <td>  No</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>  No</td>\n",
        "      <td> Yes</td>\n",
        "      <td>  No</td>\n",
        "      <td>  No</td>\n",
        "      <td> Some</td>\n",
        "      <td>   $</td>\n",
        "      <td>  No</td>\n",
        "      <td>  No</td>\n",
        "      <td>  Burger</td>\n",
        "      <td>  0-10</td>\n",
        "      <td> Yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> Yes</td>\n",
        "      <td>  No</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Full</td>\n",
        "      <td>   $</td>\n",
        "      <td> Yes</td>\n",
        "      <td>  No</td>\n",
        "      <td>    Thai</td>\n",
        "      <td> 10-30</td>\n",
        "      <td> Yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> Yes</td>\n",
        "      <td>  No</td>\n",
        "      <td> Yes</td>\n",
        "      <td>  No</td>\n",
        "      <td> Full</td>\n",
        "      <td> $$$</td>\n",
        "      <td>  No</td>\n",
        "      <td> Yes</td>\n",
        "      <td>  French</td>\n",
        "      <td>   &gt;60</td>\n",
        "      <td>  No</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td>  No</td>\n",
        "      <td> Yes</td>\n",
        "      <td>  No</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Some</td>\n",
        "      <td>  $$</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Italian</td>\n",
        "      <td>  0-10</td>\n",
        "      <td> Yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>  No</td>\n",
        "      <td> Yes</td>\n",
        "      <td>  No</td>\n",
        "      <td>  No</td>\n",
        "      <td> None</td>\n",
        "      <td>   $</td>\n",
        "      <td> Yes</td>\n",
        "      <td>  No</td>\n",
        "      <td>  Burger</td>\n",
        "      <td>  0-10</td>\n",
        "      <td>  No</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>  No</td>\n",
        "      <td>  No</td>\n",
        "      <td>  No</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Some</td>\n",
        "      <td>  $$</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Yes</td>\n",
        "      <td>    Thai</td>\n",
        "      <td>  0-10</td>\n",
        "      <td> Yes</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>  No</td>\n",
        "      <td> Yes</td>\n",
        "      <td> Yes</td>\n",
        "      <td>  No</td>\n",
        "      <td> Full</td>\n",
        "      <td>   $</td>\n",
        "      <td> Yes</td>\n",
        "      <td>  No</td>\n",
        "      <td>  Burger</td>\n",
        "      <td>   &gt;60</td>\n",
        "      <td>  No</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "   alternatives  bar  Fri hungry patrons    $ rain reservation     type  \\\n",
        "1           Yes   No   No    Yes    Some  $$$   No         Yes   French   \n",
        "2           Yes  Yes  Yes    Yes    Full  $$$   No         Yes  Italian   \n",
        "3            No   No   No     No    None    $   No          No     Thai   \n",
        "4           Yes  Yes  Yes    Yes    Full    $   No          No   Burger   \n",
        "5           Yes   No   No    Yes    Full    $   No          No     Thai   \n",
        "6            No  Yes   No     No    Some    $   No          No   Burger   \n",
        "7           Yes   No  Yes    Yes    Full    $  Yes          No     Thai   \n",
        "8           Yes   No  Yes     No    Full  $$$   No         Yes   French   \n",
        "9            No  Yes   No    Yes    Some   $$  Yes         Yes  Italian   \n",
        "10           No  Yes   No     No    None    $  Yes          No   Burger   \n",
        "11           No   No   No    Yes    Some   $$  Yes         Yes     Thai   \n",
        "12           No  Yes  Yes     No    Full    $  Yes          No   Burger   \n",
        "\n",
        "      eta eat?  \n",
        "1    0-10  Yes  \n",
        "2   10-30   No  \n",
        "3    0-10   No  \n",
        "4   30-60  Yes  \n",
        "5   30-60   No  \n",
        "6    0-10  Yes  \n",
        "7   10-30  Yes  \n",
        "8     >60   No  \n",
        "9    0-10  Yes  \n",
        "10   0-10   No  \n",
        "11   0-10  Yes  \n",
        "12    >60   No  "
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A training set of 12 examples is shown above. We want a tree that is consistent with the examples and is as small as possible. Unfortunately, no matter how we measure size, it is an intractable problem to find the smallest consistent tree; there is no way to efficiently search through the $2^{2^n}$ trees. \n",
      "\n",
      "However, with some simple heuristics we can find a good approximate solution: a small (but not smallest) consistent tree. The <b>Decision-Tree-Learning</b> algorithm adopts a greedy divide-and-conquer strategy: always test the most important attribute first. By \"most important attribute\" we mean the one that makes the most difference to the classification of an example. For example, 'type' is a poor attribute, because it leaves us with four possible outcomes, each of which has the same number of positive as negative examples. On the other hand, we see that 'patrons' is a fairly important attribute, because if the value is <i>None</i> or <i>Some</i>, then we are left with example sets for which we can answer definately.\n",
      "\n",
      "There are four cases to consider for these recursive problems:\n",
      "<ol>\n",
      "<li>If the reamining examples are all positive (or negative), then we are done: we can answer <i>Yes</i> or <i>No</i>.</li>\n",
      "<li>If there are some positive and some negative examples, then choose the best attribute to split them.</li>\n",
      "<li>If there are no examples left, it means that no example has been observed for this combination of attribute values, and we return a default value calculated from the plurality classification of all the examples that were used in constructing the node's parent. These are passed along in the variable <i>parent_examples</i></li>\n",
      "<li>If there are no attributes left, but both positive and negative examples, it means that these examples have exactly the same description, but different classifications. This can happen because there is an error or <b>noise</b> in the data; because the domain is nondeterministic; or because we can't observe an attribute that would distinguish the examples. The best we can do is return the plurality classification of the remaining examples.</li>\n",
      "</ol>\n",
      "\n",
      "How do we pick the best attribute to split on? We will use the notion of information gain, which is defined in terms of <b>entropy</b>, the fundamental quantity in information theory. Entropy is a measure of the uncertainty of a random varaible; acquisition of information corresponds to a reduction in entropy. A random variable with only one value -- a coin that always comes up heads -- has no uncertainty and thus its entropy is defined as zero; thus, we gain no information by observing its value. A flip of a coin is equally likely to come up heads or tails, 0 or 1, and this counts as \"1 bit\" of entropy. In general, the entropy of a random variable V with values $v_k$, each with probability $\\mathbb{P}(v_k)$, is defined as\n",
      "\n",
      "$$\\text{Entropy:  } H(V) = \\sum_k \\mathbb{P}(v_k)log_2 \\frac 1 {\\mathbb{P}(v_k)}= - \\sum_k \\mathbb{P}(v_k)log_2  {\\mathbb{P}(v_k)}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It will help to define $B(q)$ as the entropy of a Boolean random variable that is true with probabilty $q$:\n",
      "\n",
      "$$B(q) = -(q log_2 q + (1-q) log_2 (1-q))$$\n",
      "\n",
      "If a training set contains $p$ positive eamples and $n$ negative examples, then the entropy of the goal attribute on the whole set is (check this)\n",
      "\n",
      "$$H(Goal) = B\\left(\\frac p {p+n} \\right).$$ \n",
      "\n",
      "The restaurant training set above has $n=p=6$, so the corresponding entropy is $B(0.5)$ or exactly 1 bit. \n",
      "\n",
      "An attribute $A$ with $d$ distinct values divides the training set $E$ into subsets $E_1,...,E_d$. Each subset $E_K$ has $p_k$ positive examples and $n_k$ negative examples, so if we go along that branch, we will need an additional $B(p_k/(p_k + n_k))$ bits of information to answer the question. A randomly chosen example from the training set has the $k$th value for the attribute with probability (p_k + n_k)/(p+n), so the expected entropy remaining after testing attribute A is\n",
      "\n",
      "$$Remainder(A) = \\sum_{k=1}^d \\frac {p_k + n_k}{p+n} B \\left( \\frac {p_k}{p_k+n_k}\\right).$$\n",
      "\n",
      "The <b>information gain</b> from the attribute test on $A$ is the expected reduction in entropy:\n",
      "\n",
      "$$Gain(A) = B\\left( \\frac {p}{p+n}\\right) - Remainder(A)$$\n",
      "\n",
      "In fact $Gain(A)$ is just what we need to implement the importance function. "
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bool_entropy(q):\n",
      "    \"\"\"implementing it, like the book said\"\"\"\n",
      "    if((q == 0) or (q == 1)): \n",
      "        return 0\n",
      "    else:\n",
      "        return -(q*log2(q) + (1-q)*log2(1-q))\n",
      "\n",
      "def vectorize_attributes(attr):\n",
      "    \"\"\"try this on target, it'll return a tuple (2, [0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1])\n",
      "    the first number represents how many values the output vector has\n",
      "    the vector in this case is yes or no... and here we see it was turned into 0s and 1s.\n",
      "    But notice that the returned vector attributes have no relation to the input. For example, here,\n",
      "    0 corresponds to 'Yes', and 1 corresponds to 'No' \n",
      "    \"\"\"\n",
      "    i = 0\n",
      "    seen = {}\n",
      "    vector = []\n",
      "    for e, a in enumerate(attr):\n",
      "        if a in seen:\n",
      "            vector.append(seen[a])\n",
      "        else:\n",
      "            seen[a] = i\n",
      "            vector.append(i)\n",
      "            i = i+1     \n",
      "    return (i, vector)        \n",
      "               \n",
      "def importance(data, target):\n",
      "    #print(data)\n",
      "    #print (target)\n",
      "    length = len(target)\n",
      "    remainder = 100\n",
      "    out = ''\n",
      "    for a in data.columns:\n",
      "        temp = 0\n",
      "        number, vector = vectorize_attributes(data[a])\n",
      "        attr_data = {}\n",
      "        for i in range(number):\n",
      "            attr_data[i] = [0, 0]          \n",
      "        for i in range(len(vector)):\n",
      "            attr_data[vector[i]][0] += 1\n",
      "            attr_data[vector[i]][1] += target[i]\n",
      "        for i in range(number):\n",
      "            temp += attr_data[i][0]*bool_entropy(attr_data[i][1]/attr_data[i][0])/length \n",
      "        if (temp < remainder):\n",
      "            out = a\n",
      "            remainder = temp\n",
      "        #print(a,temp,'\\n')    \n",
      "    return out    \n",
      "\n",
      "\n",
      "data =  (df.T[:10]).T\n",
      "num, target = vectorize_attributes(df['eat?'])\n",
      "\n",
      "importance(data,target)  \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 174,
       "text": [
        "'patrons'"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import collections #http://stackoverflow.com/questions/3009935/looking-for-a-good-python-tree-data-structure\n",
      "\n",
      "def Tree():\n",
      "    return collections.defaultdict(Tree)\n",
      "\n",
      "def decision_tree_learning(data, target, parent_target, attr):\n",
      "    if (data.values == None):\n",
      "        print('woh...')\n",
      "        return mean(parent_target)\n",
      "    elif((sum(target) == 0) or (sum(target) == len(target))):\n",
      "        #print(target, sum(target), len(target))\n",
      "        print(\"classified\")\n",
      "        return target[0]\n",
      "    elif (attr == []):\n",
      "        print(\"no more attributes...\")\n",
      "        return mean(target)\n",
      "    else:\n",
      "        a = importance(data, target)\n",
      "        t = Tree()\n",
      "        t[0] = a\n",
      "        num, vector = vectorize_attributes(data[a])\n",
      "        old_df = data\n",
      "        \n",
      "        \n",
      "        print(a)\n",
      "        #print(old_df)\n",
      "        for i in range(num):\n",
      "            #print(data)\n",
      "            #print(data[array(vector) == i])\n",
      "            df = data[array(vector) == i]\n",
      "            tar = array(target)[array(vector) == i]\n",
      "            #print(df, tar)\n",
      "            df = df.drop(a,axis=1)\n",
      "            \n",
      "            t[1][i] = decision_tree_learning(df, tar, old_df, df.columns)\n",
      "        return t\n",
      "        \n",
      "            \n",
      "decision_tree_learning(data, target, data, data.columns)        \n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "patrons\n",
        "classified\n",
        "hungry\n",
        "type\n",
        "classified\n",
        "classified\n",
        "Fri\n",
        "classified\n",
        "classified\n",
        "classified\n",
        "classified\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 175,
       "text": [
        "defaultdict(<function Tree at 0xad96fd1c>, {0: 'patrons', 1: defaultdict(<function Tree at 0xad96fd1c>, {0: 0, 1: defaultdict(<function Tree at 0xad96fd1c>, {0: 'hungry', 1: defaultdict(<function Tree at 0xad96fd1c>, {0: defaultdict(<function Tree at 0xad96fd1c>, {0: 'type', 1: defaultdict(<function Tree at 0xad96fd1c>, {0: 1, 1: 0, 2: defaultdict(<function Tree at 0xad96fd1c>, {0: 'Fri', 1: defaultdict(<function Tree at 0xad96fd1c>, {0: 1, 1: 0})})})}), 1: 1})}), 2: 1})})"
       ]
      }
     ],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = Tree()\n",
      "t[0] = 'root'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t[1][0] = 'node?'\n",
      "t[1][1] = 'another node'\n",
      "t[1][2] = 'still another'\n",
      "t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 119,
       "text": [
        "defaultdict(<function Tree at 0xad9956a4>, {0: 'root', 1: defaultdict(<function Tree at 0xad9956a4>, {0: 'node?', 1: 'another node', 2: 'still another'})})"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}