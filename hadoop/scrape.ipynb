{
 "metadata": {
  "name": "",
  "signature": "sha256:7b75fb8be6ac8fc877ac7efaee0c9ba14ad8afbbe6062bdefd30e9426602bc29"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lxml import html\n",
      "import requests\n",
      "page = requests.get('http://docs.python-guide.org/en/latest/scenarios/scrape/')\n",
      "tree = html.fromstring(page.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree.xpath('//p/text()')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "['Web sites are written using HTML, which means that each web page is a\\nstructured document. Sometimes it would be great to obtain some data from\\nthem and preserve the structure while we\u2019re at it. Web sites don\u2019t always\\nprovide their data in comfortable formats such as ',\n",
        " ' or ',\n",
        " '.',\n",
        " 'This is where web scraping comes in. Web scraping is the practice of using a\\ncomputer program to sift through a web page and gather the data that you need\\nin a format most useful to you while at the same time preserving the structure\\nof the data.',\n",
        " ' is a pretty extensive library written for parsing\\nXML and HTML documents very quickly, even handling messed up tags in the\\nprocess. We will also be using the\\n',\n",
        " ' module instead of the\\nalready built-in urllib2 module due to improvements in speed and readability.\\nYou can easily install both using ',\n",
        " ' and\\n',\n",
        " '.',\n",
        " 'Let\u2019s start with the imports:',\n",
        " 'Next we will use ',\n",
        " ' to retrieve the web page with our data,\\nparse it using the ',\n",
        " ' module and save the results in ',\n",
        " ':',\n",
        " ' now contains the whole HTML file in a nice tree structure which\\nwe can go over two different ways: XPath and CSSSelect. In this example, we\\nwill focus on the former.',\n",
        " 'XPath is a way of locating information in structured documents such as\\nHTML or XML documents. A good introduction to XPath is on\\n',\n",
        " ' .',\n",
        " 'There are also various tools for obtaining the XPath of elements such as\\nFireBug for Firefox or the Chrome Inspector. If you\u2019re using Chrome, you\\ncan right click an element, choose \u2018Inspect element\u2019, highlight the code,\\nright click again and choose \u2018Copy XPath\u2019.',\n",
        " 'After a quick analysis, we see that in our page the data is contained in\\ntwo elements - one is a div with title \u2018buyer-name\u2019 and the other is a\\nspan with class \u2018item-price\u2019:',\n",
        " 'Knowing this we can create the correct XPath query and use the lxml\\n',\n",
        " ' function like this:',\n",
        " 'Let\u2019s see what we got exactly:',\n",
        " 'Congratulations! We have successfully scraped all the data we wanted from\\na web page using lxml and Requests. We have it stored in memory as two\\nlists. Now we can do all sorts of cool stuff with it: we can analyze it\\nusing Python or we can save it to a file and share it with the world.',\n",
        " 'Some more cool ideas to think about are modifying this script to iterate\\nthrough the rest of the pages of this example dataset, or rewriting this\\napplication to use threads for improved speed.',\n",
        " '\\n  This opinionated guide exists to provide both novice and expert Python developers a best-practice handbook to the installation, configuration, and usage of Python on a daily basis.\\n',\n",
        " 'Receive updates on new releases and upcoming projects.',\n",
        " '\\n    If you enjoy this guide, consider supporting the author ',\n",
        " ':\\n',\n",
        " '\\n  ',\n",
        " '\\n',\n",
        " '\\n    Enter search terms or a module, class or function name.\\n    ']"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tree.xpath('//a/h')\n",
      "for elt in tree.xpath('//a'):\n",
      "    print(elt.attrib['href'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "../../genindex/\n",
        "../cli/\n",
        "../web/\n",
        "../../\n",
        "#html-scraping\n",
        "#web-scraping\n",
        "#lxml-and-requests\n",
        "http://lxml.de/\n",
        "http://docs.python-requests.org/en/latest/\n",
        "http://www.w3schools.com/xpath/default.asp\n",
        "http://python-guide.org\n",
        "http://tinyletter.com/kennethreitz\n",
        "https://www.gittip.com/kennethreitz/\n",
        "../../\n",
        "#\n",
        "#web-scraping\n",
        "#lxml-and-requests\n",
        "../../\n",
        "../web/\n",
        "../cli/\n",
        "../../_sources/scenarios/scrape.txt\n",
        "http://kennethreitz.com/pages/open-projects.html\n",
        "http://creativecommons.org/licenses/by-nc-sa/3.0/\n",
        "https://github.com/kennethreitz/python-guide\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lxml import html\n",
      "import requests\n",
      "\n",
      "def scrape(seed = \"http://stackoverflow.com/questions/15272087/extract-href-values-with-xpath-on-python-2-7\", depth = 1):\n",
      "    \n",
      "    page = requests.get(seed)\n",
      "    tree = html.fromstring(page.text)\n",
      "    text = tree.xpath('//p/text()')\n",
      "    print(' '.join(text))\n",
      "    if(depth>0):\n",
      "        for elt in tree.xpath('//a'):\n",
      "            try:\n",
      "                link = elt.attrib['href']\n",
      "                if(link[:4] == 'http'): \n",
      "                    scrape(link, depth - 1)\n",
      "            except KeyError:\n",
      "                pass\n",
      " \n",
      "scrape()    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Quick and simple: How can i extract \"some content\" and \"click me\" with xpath on python? So far i have the following ( extract only \"some content\" from href results): Thanks in adavance. You can only select one or the other using XPath, but you could select all   elements and then pick off the   attribute and text content like this: \r\n",
        "By posting your answer, you agree to the   and  . asked viewed \r\n",
        "\t\t\t                         \r\n",
        "\t\t\t                     active\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "The core goal of Stack Exchange is education. Everything we build is geared toward helping people learn from one another \u2014 not just the nuts and bolts of their profession or passion, but the universal skills of how to better communicate and learn. As we\u2019ve grown as a company, we\u2019ve benefited from many resources to assist in educating developers out of our office space, including hosting   and partnering with the Flatiron School and Fog Creek for a  . Today, we\u2019re excited to announce our partnership with the  , Mayor de Blasio\u2019s new initiative designed to increase the number of qualified candidates for open tech positions in New York City. The city has brought together   and asked us to do two things: On the first point, we\u2019re excited that our VP of Engineering, David Fullerton, will be sitting in on quarterly meetings with other tech industry leaders convened by Mayor de Blasio, where we hope we can help to represent the developer voice and to share what skills and technologies we know are most in-demand. For the second, we\u2019ve already brought in a bunch of (awesome) NYC companies \u2014 including Trello, Kickstarter, Foursquare, Tumblr, and Control Group \u2014 who will build and teach a new curriculum of programmer \u201csoft skills\u201d to graduates of public computer science programs in New York (starting with the CUNY system) that will better equip them as professional developers. The goal is to make sure that anyone in this city with a passion for technology, no matter who they are or what neighborhood they grew up in, can get the mentoring, training, and support they need to succeed as a developer. As you probably know, there\u2019s a vast disparity between open tech jobs and qualified developers in today\u2019s market. At last count, there are   for every one job-seeking developer. With New York City\u2019s current tech job count teetering at around 300,000 job openings, we need to increase the number of good candidates or a lot of \u00a0websites aren\u2019t going to get built. The city needs developers. And this happens to be an area that we know a thing or two about. Our goal is to support and empower developers, no matter where they may be in their programming careers. Despite our well-known  , our founder has always been a particular proponent of building great places in New \u00a0York for those developers who  . Like many tech companies, we\u2019ve been giving a lot of thought to how we can promote inclusion, both internally and in the tech community as a whole. We don\u2019t pretend to have figured it all out, but this is just one thing we\u2019re excited to share. As always, we welcome any ideas you may have.   Welcome to Stack Exchange Podcast #62, recorded live on January 20th\u2013with a\u00a0 . Today\u2019s podcast was brought to you by the American Venture Capital Association. With you today are our hosts Jay Hanlon, David Fullerton, and Joel Spolsky. Let\u2019s jump right in: we made\u00a0 ! Andreessen Horowitz has invested a pile of money in our little company so we can improve our \u2018programmer forums\u2019. Precisely none of the pile of money is going into Jay\u2019s raise, but one of those dollars\u00a0 . So, the (forty) million dollar question:\u00a0 \n",
        " We intend to (continue) spending money on  . Our goal is to\u00a0 , and we want to do that without selling crazy-takeover-animated-bonzaibuddy-ads that feel like reading a newspaper on the subway (according to Joel), so we\u2019re getting money from investors instead. How are we going to make this happen? We plan to revisit the developer side of the Careers equation and figure out how to make that better. More features to let programmers search and filter for interesting jobs, update the way profiles work, etc. \u2013 more of the stuff we were going to work on anyway. Careers is already a very developer-focused product: we limit the things our employers can do heavily based on what drives programmers nuts. For example, we only let employers contact a limited number of candidates  , and we disallow contingency recruiters. (A pox on all of their houses.)  You can get a Careers profile\u00a0 . We filter the applications to make sure only real programmers end up with profiles on Careers. Time to take some questions from the peanut gallery! Well, a few bits. This cash will allow us to hire more designers, so more sites can graduate and get beautiful site designs. We\u2019ll get to hire more people to hit more of our goals at the same time. For example, one of the things we\u2019re actively working on now is   on Q&A sites. Have we mentioned lately that\u00a0 ? Our most urgent need is for product managers, and you can apply for that job even if you\u2019ve never had \u2018product manager\u2019 in your job title before.\n",
        " And we\u2019re out of questions. So what else is going on these days?   And some  . How about new features? We\u2019re experimenting with\u00a0 \u00a0to help sort questions into \u201chopeless and needs to be burninated\u201d and \u201ccould be passable with some editing\u201d buckets. Things in the triage queue won\u2019t show up on the homepage until they\u2019ve been approved.\u00a0 . Joel wants to sign off, but first make sure you check out\u00a0 . (Since this podcast was recorded,\u00a0 \u00a0has also graduated with a slick new theme.) Thanks for wasting an hour on the Stack Exchange Podcast Episode #62, brought to you by the American Venture Capital Association.   Stack Overflow Careers was announced   with a simple mission statement: We believe that  To help you find a job you love, we need to match you with the right job at the right time. We do that by  , and by showing you relevant job ads from our   on Stack Overflow. With   that advertise on Stack Overflow Careers, we\u2019re getting closer to our goal of having a great job for every developer. Until today, the job ads that we show on Stack Overflow were pretty stupid: they targeted solely based on location, and ignored all the other information about what you\u2019re looking for and what kind of job it is. They didn\u2019t even care about whether the job was in a technology that you were interested in. So today* we\u2019re launching the first step in showing you jobs that we think are an actual match for you. Many of you will start noticing that the jobs you see aren\u2019t just in your area, but are related to the question you\u2019re viewing, a question you\u2019ve answered, or something you\u2019ve asked about. We\u2019re using this little bit of data, along with the location data we were already using, to predict what type of job you\u2019re more likely to want to apply to. We then do some  based on this information to target mobile jobs at mobile devs, front-end web development jobs at front-end devs, and even more complex stuff based on technology stack and specific tags. It\u2019s difficult to show you an example of a targeted ad. We haven\u2019t changed much about the ad design or even how the job is displayed in the ads. However, we   show you the other side, how the employer is targeting their jobs. This is all organized into three tiers of targeting criteria: It\u2019s really that simple. Once employers fill out a targeting profile for a job, we\u2019ll try and predict which of those jobs you\u2019ll be interested in. Hopefully this doesn\u2019t change much about how you use Stack Overflow in your daily life. Job ads are only a small part of our page content, but we hope this launch will improve your odds of seeing the right job opportunity at the right time. So far it appears to be working. Initial testing of targeted jobs over the past few months have demonstrated significant progress toward our goal of showing relevant job ads to each developer, as clickthrough rates increased 21-30%. Not bad for a V1! We also want to let you know exactly how we\u2019re targeting jobs, so our newly created data team will be talking about building out the infrastructure for this project, and all the details of what went into it.\u00a0You can follow these posts on   starting today.\u00a0  will also be adding to this series later this week and next. Additionally, if you want to see your personal prediction data, or if you want to disable predictions, you can do that from the  . If you want more details on how this works for employers, go visit our  .\u00a0If you want to dive right in, you can post a job now and  .\u00a0And if you already have a job running, you can edit it to add targeting for the rest of its run. That\u2019s it! As always, if you have questions or comments feel free to post on  .   (Note: This is a   from  ).  Today   is pleased to announce that we have raised $40 million, mostly from  . Everybody wants to know what we\u2019re going to do with all that money. First of all, of course we\u2019re going to gold-plate the Aeron chairs in the office. Then we\u2019re going to upgrade the game room, and we\u2019re already sending lox platters to our highest-rep users. But I\u2019ll get into that in a minute. First, let me catch everyone up on what\u2019s happening at Stack Exchange. In 2008,   and I set out to fix a problem for programmers. At the time, getting answers to programming questions online was super annoying. The answers that we needed were hidden behind paywalls, or buried in thousands of pages of stale forums. So we set out to build   with a single-minded, compulsive, fanatical obsession with serving programmers by building a better Q&A site. Everything about how Stack Overflow works today was designed to make programmers\u2019 jobs easier. We let members vote up answers, so we can show you the best answer first. We don\u2019t allow opinionated questions, because they descend into flame wars that don\u2019t help people who need an answer right now. We have scrupulously avoided any commercialization of our editorial content, because we want to have a site that programmers can trust. Heck, we don\u2019t even allow animated ads, even though they are totally standard on every other site on the Internet, because it would be disrespectful to programmers to strain their delicate eyes with a dancing monkey, and we can\u2019t serve them 100% if we are distracting them with a monkey. That would only be serving them 98%. And we\u2019re OBSESSED, so 98% is like, we might as well close this all down and go drive taxis in Las Vegas. Anyway, it worked! Entirely thanks to you. An insane number of developers stepped up to pass on their knowledge and help others. Stack Overflow quickly grew into the largest, most trusted repository of programming knowledge in the world. Quickly, Jeff and I discovered that serving programmers required more than just code-related questions, so we built   and  . And when that still didn\u2019t satisfy your needs, we set up   so the community could create sites on new topics. Now when a programmer has to set up a server, or a PC, or a database, or Ubuntu, or an iPhone, they have a place to go to ask those questions that are full of the people who can actually help them do it. But you know how programmers are. They \u201chave babies.\u201d\u00a0 Or \u201ctake pictures of babies.\u201d So our users started building Stack Exchange sites on unrelated topics, like   and  , because the programmers we were serving expected\u2014nay, demanded!\u2014a place as awesome as Stack Overflow to ask about baby feeding schedules and f-stops and whatnot. And we did such a good job of serving programmers that a few smart non-programmers looked at us and said, \u201cBehold! I want that!\u201d and we thought, hey!\u00a0 What works for developers should work for a lot of other people, too, as long as they\u2019re willing to think like developers, which is the best way to think. So, we decided that anybody who wants to get with the program is welcome to join in our plan. And these sites serve their own communities of, you know,  , or what have you, and make the world safer for the Programmer Way Of Thinking and thus serve programmers by serving bicycle mechanics. In the five years since then, our users have built 133 communities. Stack Overflow is still the biggest. It reminds me of those medieval maps of the ancient world. The kind that shows a big bustling city (Jerusalem) smack dab in the middle, with a few smaller settlements around the periphery. (Please imagine Gregorian chamber music). View of Jerusalem Stack Overflow is the big city in the middle. Because the programmer-city worked so well, people wanted to ask questions about other subjects, so we let them build other Q&A villages in the catchment area of the programmer-city. Some of these Q&A villages became cities of their own. The     barely even have any programmers and they speak their own weird language. They are math-Jerusalem. They make us very proud. Even though they don\u2019t directly serve programmers, we love them and they bring a little tear to our eyes, like the other little villages, and they\u2019re certainly making the Internet\u2014and the world\u2014better, so we\u2019re devoted to them. One of these days some of those villages will be big cities, so we\u2019re committed to keeping them clean, and pulling the weeds, and helping them grow. But let\u2019s go back to programmer Jerusalem, which\u2014as you might expect\u2014is full of devs milling about, building the ENTIRE FUTURE of the HUMAN RACE, because, after all,  \u00a0and writing software is just writing a script for how the future will play out. So given the importance of software and programmers, you might think they all had wonderful, satisfying jobs that they love. But sadly, we saw that was not universal. Programmers often have crappy jobs, and their bosses often poke them with sharp sticks. They are underpaid, and they aren\u2019t learning things, and they are sometimes overqualified, and sometimes underqualified. So we decided we could actually make all the programmers happier if we could move them into better jobs. That\u2019s why we built  . This was the first site that was built for developers, not recruiters. We banned the scourge of contingency recruiters (even if they have big bank accounts and are just LINING UP at the Zion Gate trying to get into our city to feed on programmer meat, but, to hell with them). We are SERVING PROGRAMMERS, not spammers. Bye Felicia. The sites are still growing like crazy. By our measurements, the Stack Exchange network is already in the top 50 of all US websites, ranked by number of unique visitors, with traffic still growing at 25% annually. The company itself has passed 200 employees worldwide, with big plush offices in Denver, New York, and London, and dozens of amazing people who work from the comfort of their own homes. (By the way, if 200 people seems like a lot, keep in mind that more than half of them are working on Stack Overflow Careers). We could just slow down our insane hiring pace and get profitable right now, but it would mean foregoing some of the investments that let us help more developers. To be honest, we literally can\u2019t keep up with the features we want to build for our users. The code is not done yet\u2014we\u2019re dedicating a lot of resources to the core Q&A engine. This year we\u2019ll work on improving the experience for both new users and highly experienced users. And let\u2019s not forget Stack Overflow Careers. I believe it is, bar-none, the single best job board for developer candidates, which should\u00a0 automatically make it the best place for employers to find developer talent. There\u2019s a LOT more to be done to serve developers here and we\u2019re just getting warmed up. So that\u2019s why we took this new investment of $40m. We\u2019re ecstatic to have Andreessen Horowitz on board. The partners there believe in our idea of programmers taking over (it was Marc Andreessen who coined the phrase \u201cSoftware is eating the world\u201d). Chris Dixon has been a personal investor in the company since the beginning and has always known we\u2019d be the obvious winner in the Q&A category, and will be joining our board of directors as an observer. This is not the first time we\u2019ve raised money; we\u2019re proud to have previously taken investments from Union Square Ventures, Index Ventures, Spark Capital, and Bezos Expeditions. We only take outside money when we are 100% confident that the investors share our philosophy completely and after our lawyers have done a ruthless (sorry, investors) job of maintaining control so that it is literally impossible for anyone to mess up our vision of fanatically serving the people who use our site, and continuing to make the Internet a better place to get expert answers to your questions. For those of you who have been with us since the early days of Our Incredible Journey, thank you. For those of you who are new, welcome. And if you want to learn more, check out our  . Or  ! \u00a0   There was a time where it seemed like we barely even needed to talk about this: Joel had  , the Internet agreed that private offices were the future, and only incompetent management (or a tight budget) was still putting developers in cubicle farms. A glorious future lay before us. \n",
        " Unfortunately, that\u2019s not quite how it turned out. Open plans have been surprisingly hard to kill, despite research showing that they\u2019re  ,  , and  . The response so far seems to have been to double down and make it, if anything, worse: cubicles are now decidedly un-cool so no-wall open offices are all the rage, and Facebook brags that its new building will be  , consisting of a single,   open room. The result is that today Stack Exchange is decidedly lonely if not quite alone in offering private offices to our developers (at least the half who work in the office; the other half  ). Suddenly we\u2019re the ones who look a bit old-fashioned: isn\u2019t that the old-school Microsoft approach? Doesn\u2019t it make us less creative? How can we stay fast and agile if people keep disappearing into offices  ? We\u2019re pretty sure it doesn\u2019t do any of these things, and in fact we believe it has a lot to do with how we think about work and our developers. \u2019s management philosophy is deceptively simple: hire smart people who get things done, and  . The role of management is to give the people who actually do the work \u2014 the developers, designers, sysadmins, etc. \u2014 all the tools they need to get their jobs done, and then trust them to do the job! This means we give you the space and expect you to find your own rhythm of work. With a private office, you\u2019re in control of your space and attention: you can choose when to close the door and avoid interruptions, and when to go play  , talk with coworkers or work out of the  . In an open office you\u2019re at the mercy of the people around you: if they\u2019re talking, the best you can do is crank up your headphones and hope to drown them out, and if they\u2019re playing foosball then good luck. Everybody has their own rhythm. People come in at different times, take breaks at different times, need to socialize at different times, and have their most productive hours at different times. Management\u2019s job is to accommodate that and create a space where all those conflicting needs don\u2019t congeal into a persistent hum of distraction \u2014   to enforce some top-down ideal of openness and creativity. Private offices put the people who do the actual work  . \n",
        " We are an online company: we\u2019ve been remote from day one and still to this day over half of the team (aside from sales) works from home. The only way to make that work is to keep the nexus of activity online: in chat rooms, Google Hangouts, Trello boards, etc. This keeps everyone on equal footing, whether you\u2019re in the office or working from home. Want to know what\u2019s going on? Just check Trello and chat. Don\u2019t go hang out around the watercooler. This creates a magnificent culture of non-distraction. Whenever we get a new hire in the office, I make it a point to sit down with them in their first week and explain that they  . Instead, ping them in chat and then jump on a hangout. The result is exactly the sort of culture that open offices are supposed to promote but better: This really is the best of both worlds, and one of the reasons that I\u2019m a big advocate of   even if nobody works remote. And a big part of what makes it possible if you\u2019re working out of an office is having a door you can close so you\u2019re not distracting your coworkers. \n",
        " The result is that we get a lot of work done and individuals are fantastically productive. The only thing missing is to make sure that we\u2019re facilitating those cross-team connections that open offices pretend to get you for free. We solve that in a few simple ways: daily lunch together in the office, weekly \u201cBeer Bashes\u201d, and an annual company meetup. Joel has written a lot about   and we\u2019re still big believers in it. Some people get a little weirded out by this so I\u2019ll clarify: lunch together is not required, but anyone who skipped it completely would be missing out on some great food. At Stack Exchange HQ in New York we\u2019re lucky enough to have a   and our own   and the results are pretty amazing. Eating lunch together every day is a great way to connect with coworkers you wouldn\u2019t otherwise have talked to, though it doesn\u2019t quite tie in the remote employees which is what makes the other approaches so important. Friday \u201cBeer Bashes\u201d have long been another in-office tradition: grab a tasty beverage (alcoholic or not, nobody really cares) and hang out with some of your esteemed colleagues on Friday afternoon before taking off for the weekend. Recently we\u2019ve been experimenting with Remote Beer Bashes via Google Hangouts, with some  . Now even the remote people can join in and have some fun, even if it\u2019s   or   in their time zones. Finally we have an  . We could write a whole post on this, but one of the points we make every year is that the primary goal of the meetup is to meet people and hang out \u2014 any work done is merely a side benefit. This last year we had a pretty great mix of  ,  , and a strange obsession with   (oh, and an impromptu   when we were hit with a novel DDoS attack). The whole thing was a huge success (even the war room) and really got a lot of different teams talking to each other and solving problems together. \n",
        " Now, of course, the caveat: this is what works for us, and we understand it\u2019s not for everyone. Maybe some places really are more creative because they have open plans. We don\u2019t actually even give   private offices: some people are doubled up in offices, and the sales and marketing teams sit in larger open spaces because they feel that\u2019s an important part of how they work. But it\u2019s continually astonishing to me that more companies aren\u2019t talking about private offices for developers, and that open plans have become the expected norm in the industry. At the very least we should be considering all the benefits that private offices provide. Oh, and did I mention  ? If this sounds like the kind of place you\u2019d like to work \u2014 whether out of the office or from home \u2014   across all three offices and remote. In closing, I\u2019ll leave you with a few choice pictures of our office. If you\u2019d like to explore more, check out the  . We also have sales offices in   and   which you can check out. \n",
        " \n",
        " \n",
        " \n",
        " Oh, and if you\u2019re worried about our remote developers, we make sure to set them up with some pretty sweet equipment too: \n",
        " \n",
        " \n",
        "   Stack Exchange \u00a9 2015  are licensed under a  ."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\r\n",
        "             \r\n",
        "        "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "                             \n",
        "                             \n",
        "                         \n",
        "                             \n",
        "                             \n",
        "                         \n",
        "                             \n",
        "                             \n",
        "                         \r\n",
        "By registering, you agree to the   and  . \n",
        "                            Open ID is a service that allows you to log on to many different websites using a single identity. Find out   and  .\n",
        "\n",
        "                         Because JavaScript is disabled, you can only sign up by entering your OpenID URL manually:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "                             \n",
        "                             \n",
        "                         \n",
        "                             \n",
        "                             \n",
        "                         \n",
        "                             \n",
        "                             \n",
        "                         \n",
        "                            Open ID is a service that allows you to log on to many different websites using a single identity. Find out   and  .\n",
        "                         Because JavaScript is disabled, you can only log in by entering your OpenID URL manually:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "                             \n",
        "                             \n",
        "                         \n",
        "                             \n",
        "                             \n",
        "                         \n",
        "                             \n",
        "                             \n",
        "                         \r\n",
        "By registering, you agree to the   and  . \n",
        "                            Open ID is a service that allows you to log on to many different websites using a single identity. Find out   and  .\n",
        "\n",
        "                         Because JavaScript is disabled, you can only sign up by entering your OpenID URL manually:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-37-018a6cc8b82a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-37-018a6cc8b82a>\u001b[0m in \u001b[0;36mscrape\u001b[1;34m(seed, depth)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mlink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrib\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'http'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-37-018a6cc8b82a>\u001b[0m in \u001b[0;36mscrape\u001b[1;34m(seed, depth)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"http://stackoverflow.com/questions/15272087/extract-href-values-with-xpath-on-python-2-7\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//p/text()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert)\u001b[0m\n\u001b[0;32m    454\u001b[0m             \u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         }\n\u001b[1;32m--> 456\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    325\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m                 )\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, **response_kw)\u001b[0m\n\u001b[0;32m    491\u001b[0m             httplib_response = self._make_request(conn, method, url,\n\u001b[0;32m    492\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m                                                   body=body, headers=headers)\n\u001b[0m\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;31m# conn.request() calls httplib.*.request, not the method in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;31m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSocketTimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m             raise ConnectTimeoutError(\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m   1088\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_content_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m   1126\u001b[0m             \u001b[1;31m# default charset of iso-8859-1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iso-8859-1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1128\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body)\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1086\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body)\u001b[0m\n\u001b[0;32m    922\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmessage_body\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m             \u001b[0mmessage_body\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m             \u001b[1;31m# message_body was not a string (i.e. it is a file), and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/http/client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/site-packages/requests/packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m                                     \u001b[0mca_certs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mca_certs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                                     \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhostname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m                                     ssl_version=resolved_ssl_version)\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresolved_cert_reqs\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCERT_NONE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/site-packages/requests/packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version)\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_cert_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcertfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Platform-specific: OpenSSL with enabled SNI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[0;32m    362\u001b[0m                          \u001b[0msuppress_ragged_eofs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m                          \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m                          _context=self)\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_npn_protocols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpn_protocols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/ssl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context)\u001b[0m\n\u001b[0;32m    576\u001b[0m                         \u001b[1;31m# non-blocking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chuphay/anaconda3/lib/python3.4/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}